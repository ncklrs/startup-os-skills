---
title: Quality Assurance & Agent Coaching
impact: HIGH
tags: quality, QA, coaching, training, performance, reviews
---

## Quality Assurance & Agent Coaching

**Impact: HIGH**

Quality assurance ensures consistent, excellent customer experiences. Without QA, agent performance varies wildly and issues go undetected. Done right, QA is a coaching tool that elevates the entire team.

### The QA Framework

```
┌─────────────────────────────────────────────────────────────────┐
│                    QUALITY MEASUREMENT                           │
│  Ticket reviews, score tracking, trend analysis                 │
└──────────────────────────┬──────────────────────────────────────┘
                           │
           ┌───────────────┼───────────────┐
           ▼               ▼               ▼
    ┌─────────────┐ ┌─────────────┐ ┌─────────────┐
    │  INDIVIDUAL │ │    TEAM     │ │   PROCESS   │
    │   COACHING  │ │   TRENDS    │ │ IMPROVEMENT │
    │             │ │             │ │             │
    │ 1:1 feedback│ │ Common gaps │ │ KB updates  │
    │ Training    │ │ Best sharing│ │ Tool fixes  │
    │ Development │ │ Calibration │ │ Workflow    │
    └─────────────┘ └─────────────┘ └─────────────┘
                           │
                           ▼
              ┌───────────────────────┐
              │  IMPROVED CUSTOMER    │
              │     EXPERIENCE        │
              └───────────────────────┘
```

### QA Scorecard Dimensions

| Dimension | Weight | What It Measures |
|-----------|--------|------------------|
| **Solution Quality** | 30% | Was the answer correct and complete? |
| **Communication** | 25% | Was the message clear, professional, empathetic? |
| **Process Adherence** | 20% | Were procedures and documentation followed? |
| **Efficiency** | 15% | Was handle time appropriate for complexity? |
| **Customer Experience** | 10% | Did the interaction feel personalized and helpful? |

### Detailed Scoring Rubric

**Solution Quality (30 points)**
```
30: Perfect - Correct, complete, first-time resolution
25: Good - Correct, minor details missing
20: Adequate - Mostly correct, needed follow-up
15: Needs Work - Partially correct, customer confused
10: Poor - Wrong solution, customer frustrated
0:  Fail - Critical error, escalation required
```

**Communication (25 points)**
```
25: Excellent - Clear, warm, professional, personalized
20: Good - Clear and professional, minimal personalization
15: Adequate - Understandable, somewhat impersonal
10: Needs Work - Confusing or too casual/formal
5:  Poor - Unclear, rude, or unprofessional
0:  Fail - Inappropriate, offensive, or damaging
```

**Process Adherence (20 points)**
```
20: Perfect - All procedures followed, complete documentation
15: Good - Minor documentation gaps
10: Adequate - Some steps skipped, functional documentation
5:  Needs Work - Multiple steps skipped
0:  Fail - Critical process violation
```

**Efficiency (15 points)**
```
15: Excellent - Optimal time for complexity level
12: Good - Slightly over/under optimal time
9:  Adequate - Noticeably inefficient but reasonable
6:  Needs Work - Significant time waste
3:  Poor - Extreme inefficiency or rushing
0:  Fail - SLA breach due to handling
```

**Customer Experience (10 points)**
```
10: Delightful - Went above and beyond
8:  Good - Met expectations, professional
6:  Adequate - Functional, impersonal
4:  Needs Work - Customer had to work hard
2:  Poor - Frustrating experience
0:  Fail - Customer explicitly complained
```

### Good QA Practices

```
✓ Random sampling
  → Representative ticket mix
  → Multiple categories reviewed
  → Both good and problematic tickets

✓ Calibrated reviewers
  → Regular calibration sessions
  → Same ticket, compare scores
  → Align on standards

✓ Timely feedback
  → Reviews within 48 hours
  → Coaching within a week
  → Real-time flags for critical issues

✓ Growth-focused
  → Celebrate improvements
  → Actionable feedback
  → Development plans

✓ Data-driven
  → Track trends over time
  → Identify systemic issues
  → Measure improvement
```

### Bad QA Practices

```
✗ Gotcha culture
  → Looking for mistakes to punish
  → Agents fear QA

✗ Inconsistent standards
  → Different reviewers, different scores
  → No calibration

✗ Delayed feedback
  → Reviews from months ago
  → Issues already repeated

✗ Score obsession
  → Number without context
  → No coaching conversation

✗ Cherry-picking
  → Only reviewing easy tickets
  → Missing complex cases

✗ No positive feedback
  → Only hear about problems
  → Demotivating
```

### QA Review Workflow

```
Weekly QA Process:
┌─────────────────────────────────────────────────────────────────┐
│ Day 1-2: Ticket Selection                                        │
│  □ Pull random sample (3-5 tickets per agent)                   │
│  □ Include mix of categories and complexity                     │
│  □ Add any flagged tickets from previous week                   │
├─────────────────────────────────────────────────────────────────┤
│ Day 3-4: Review and Score                                        │
│  □ Apply scorecard to each ticket                               │
│  □ Document specific feedback points                            │
│  □ Flag exceptional (good or bad) examples                      │
├─────────────────────────────────────────────────────────────────┤
│ Day 5: Calibration and Coaching                                  │
│  □ Calibration meeting with reviewers                           │
│  □ Share scores and feedback with agents                        │
│  □ Schedule 1:1 coaching for low scores                         │
└─────────────────────────────────────────────────────────────────┘
```

### Sample Size Guidelines

| Team Size | Tickets/Agent/Week | Total Monthly |
|-----------|-------------------|---------------|
| 1-5 agents | 5 tickets | 100+ tickets |
| 6-15 agents | 3-4 tickets | 200-300 tickets |
| 16-30 agents | 2-3 tickets | 300-400 tickets |
| 30+ agents | 2 tickets | Varies |

### Calibration Session Format

```
Monthly Calibration (1 hour):
1. Pre-work: All reviewers score same 3 tickets
2. Compare scores and discuss differences
3. Align on correct interpretation of rubric
4. Update guidelines if needed
5. Document decisions for reference

Calibration Metrics:
- Score variance should be <5 points
- Major discrepancies discussed until aligned
- Track calibration quality over time
```

### Coaching Conversation Template

```
## 1:1 Coaching: [Agent Name]

**Date:** [Date]
**Review Period:** [Dates]
**Average QA Score:** [X/100]

### Strengths (Lead with positives)
- [Specific strength with example]
- [Another strength with example]

### Ticket Review
Let's look at [Ticket #X] together...
- What went well: [Specific feedback]
- Opportunity: [Specific feedback]

### Development Focus
This week, let's focus on: [One specific area]
- Why it matters: [Impact explanation]
- How to improve: [Specific actions]
- Resources: [Training, shadowing, documentation]

### Goals for Next Week
1. [Specific, measurable goal]
2. [Specific, measurable goal]

### Follow-up
- Next 1:1: [Date]
- Check-in on: [Specific item]
```

### Common Coaching Scenarios

| Issue | Coaching Approach |
|-------|-------------------|
| **Technical gaps** | Pair with specialist, assign training |
| **Communication issues** | Review examples, practice rewrites |
| **Process non-compliance** | Explain why, shadow high performers |
| **Efficiency problems** | Time management tips, tool training |
| **Empathy lacking** | Role-play exercises, customer stories |
| **Over-escalation** | Decision trees, confidence building |
| **Under-escalation** | Clear escalation criteria, safety net |

### Performance Improvement Plan

```
## Performance Improvement Plan: [Agent Name]

**Start Date:** [Date]
**Review Date:** [30/60/90 days out]
**Manager:** [Name]

### Current Performance
- QA Score: [X/100] (vs team avg [Y/100])
- Specific concerns:
  - [Issue 1]
  - [Issue 2]

### Performance Standards Required
- QA Score: [Target, e.g., 80+]
- CSAT: [Target]
- Handle time: [Target]

### Support Provided
- Weekly 1:1 coaching
- Buddy system with [Name]
- Additional training: [Specific courses]
- Reduced ticket load for [X weeks]

### Milestones
- Week 2: [Milestone and measure]
- Week 4: [Milestone and measure]
- Week 6: [Milestone and measure]
- Week 8: [Final review]

### Success Criteria
[Clear definition of what success looks like]

### Signatures
Agent: ________________  Date: _______
Manager: _______________  Date: _______
```

### QA Metrics Dashboard

| Metric | Definition | Target |
|--------|------------|--------|
| **Avg QA Score** | Team average score | 85+ |
| **Score Distribution** | % in each band | Normal curve |
| **Calibration Variance** | Reviewer agreement | <5 points |
| **Review Coverage** | % agents reviewed | 100% weekly |
| **Critical Fails** | Failed tickets | <2% |
| **Improvement Rate** | Score change over time | Positive trend |
| **QA-CSAT Correlation** | Do high QA scores = high CSAT? | Strong positive |

### Recognition Program

```
Excellence Recognition:
├── Weekly: "Ticket of the Week" - shared in team meeting
├── Monthly: Top performer award - tangible recognition
├── Quarterly: Quality champion - career development opportunity

Peer Recognition:
├── Shout-outs in Slack
├── Best practice sharing
├── Mentorship opportunities
```

### Anti-Patterns

- **Punitive QA** — Used for discipline, not development
- **Score inflation** — Everyone gets 90+, no differentiation
- **Random rubric** — Different scores for same quality
- **Feedback void** — Scores given, never discussed
- **Perfectionism** — Only 100% acceptable
- **Recency bias** — Only recent tickets reviewed
- **Volume over quality** — Too many reviews, shallow feedback
- **Ignoring top performers** — Only coaching struggling agents
